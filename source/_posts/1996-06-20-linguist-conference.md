---
layout: post
title: Annual Conference Will Draw Nearly Four Hundred Computational Linguists To UC Santa Cruz
author: Barbara McKenna
---

**If Ewe Can Sea The Errors Inn Hear Your A Head Of My Spell Checker. Eye Wont A Bettor Won.**

SANTA CRUZ, CA--Anyone who uses a spell checker with his or her  word-processing program knows that the tool, while quite handy,  misses many of the worst errors because it isn't sophisticated  enough to examine words in context. But a program currently in  development by an Edinburgh University researcher offers hope for a  smarter computer--one that would notice when the noun "ewe" is  sitting where a pronoun should be and deduce that the pronoun is  most likely "you."

The Edinburgh researcher, Andrei Mikheev, will present his  work during the 34th annual meeting of the Association for  Computational Linguistics (ACL), which takes place June 23-28 at  the University of California, Santa Cruz. Close to 400 scientists,  researchers, and scholars from business and academia are expected  to attend the conference.

Advances in computational linguistics are rapidly bridging the  communication gap between computers and their human users. At the  weeklong ACL conference, many cutting-edge advances such as  Mikheev's will be presented at some 40 workshops and lectures.  Among the innovations conference attendees will report on are the  following:

* Mikheev will present a talk on his program, which is able to  identify types of words (e.g., distinguish nouns from verbs) without  being told anything about grammar. The program works out its own  rules for classifying words by reading text and making tabulations  based on what it has observed (rather than on what it has been told  in advance to do). Not only can the program catch a correctly spelled  word out of context (as in the above sentence) but it doesn't have to  have the word stored in its memory banks before it begins the  process.

* An experimental setup devised by psycholinguist Michael  Tanenhaus that helps researchers study how we understand spoken  language. The device, which gives one an uncanny sense that it is  reading the mind of the subject using it, tracks minute eye  movements by means of a laser beam. That information is  transmitted to a computer that figures out the exact spot the  subject is looking at. The information from the computer is merged  at high speed with a video camera attached to the subject's head.  The result is a video image with crosshairs that shows exactly  where the subject's gaze goes, even for periods as short as a fifth of  a second. The tool is astonishingly effective at measuring how  quickly someone comprehends specific instructions and which words  in the instructions actually spark comprehension, second by second.  This is the most effective approach yet for looking into a human  mind to see how language comprehension is accomplished.

* A program--run on a laptop computer--that can translate  between English and Korean. Work on machine translation programs  has been going on for three decades, but the programs usually  involve European languages. It is only in recent years that there has  been progress on automatic translation between thoroughly  unrelated languages like Korean and English.

* New methods of parsing--the process of reading a sentence and  figuring out its grammatical structure and its meaning--that teach  programs to eliminate irrelevant senses of words when necessary.  (If your friend said she would wait for you at the bank, should you  look down by the river or head toward the local Wells Fargo?)

* Novel mathematical work on methods for parsing and for  measuring the success of those methods.

[Source](http://www1.ucsc.edu/news_events/press_releases/archive/95-96/06-96/062096-UCSC_conference_wil.html "Permalink to 062096-UCSC_conference_wil")
